{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e401483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import labraries\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6e51813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up chrome driver\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-automation'])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "options.add_argument('--disable-blink-features=AutomationControlled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52115799",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(\"..\\\\chromedriver-win64\\\\chromedriver.exe\")\n",
    "browser = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15b36609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the job detail page\n",
    "\n",
    "browser.get('https://www.irishjobs.ie/jobs/data-scientist?searchOrigin=Resultlist_top-search')\n",
    "time.sleep(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3598064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrape current page...\n",
      "Found 25 jobs on this page\n",
      "Processing job 1 ...\n",
      "  - Title: Data Analytics - Senior Consultant\n",
      "  - Company: N/A\n",
      "  - Experience: 0\n",
      "  - Skills: Python, R, SQL, SAS, Tableau, Power BI, Azure\n",
      "Processing job 2 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics, AWS...\n",
      "Processing job 3 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics, Hyp...\n",
      "Processing job 4 ...\n",
      "  - Title: Senior Data Analyst - Supply Chain Planning\n",
      "  - Company: N/A\n",
      "  - Experience: 12\n",
      "  - Skills: R, Power BI\n",
      "Processing job 5 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics\n",
      "Processing job 6 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: R, SQL, Tableau, Power BI, Statistics, Azure\n",
      "Processing job 7 ...\n",
      "  - Title: Senior Commercial Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics, Hyp...\n",
      "Processing job 8 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics\n",
      "Processing job 9 ...\n",
      "  - Title: Senior Machine Learning Engineer\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: Python, R, SQL, Scikit-learn, TensorFlow, PyTorch,...\n",
      "Processing job 10 ...\n",
      "  - Title: Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 0\n",
      "  - Skills: Python, R, SQL, Power BI, Statistics\n",
      "Processing job 11 ...\n",
      "  - Title: Data Analyst FTC - 6 Months\n",
      "  - Company: N/A\n",
      "  - Experience: 0\n",
      "  - Skills: Python, R, SQL, Statistics\n",
      "Processing job 12 ...\n",
      "  - Title: AI Business Process Digital Solution Area Specialist\n",
      "  - Company: N/A\n",
      "  - Experience: 0\n",
      "  - Skills: R, Machine Learning\n",
      "Processing job 13 ...\n",
      "  - Title: Vacancy | Academy & Pathway Performance Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 0\n",
      "  - Skills: R\n",
      "Processing job 14 ...\n",
      "  - Title: Senior Biostatistician – Oncology (FSP -Permanent Homebased)\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: R, SAS, Statistics, Machine Learning\n",
      "Processing job 15 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 3\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics\n",
      "Processing job 16 ...\n",
      "  - Title: Senior Data Analyst\n",
      "  - Company: N/A\n",
      "  - Experience: 25\n",
      "  - Skills: Python, R, SQL, Tableau, Power BI, Statistics, Hyp...\n",
      "Processing job 17 ...\n",
      "  - Title: Snr Data Team Lead\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: R\n",
      "Processing job 18 ...\n",
      "  - Title: Senior Clinical Data Team Lead (Senior DTL) - FSP\n",
      "  - Company: N/A\n",
      "  - Experience: 7\n",
      "  - Skills: R\n",
      "Processing job 19 ...\n",
      "  - Title: Senior Statistical Programmer (Remote - Permanent Homebased)\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: R, SAS, Statistics, Machine Learning, Databricks\n",
      "Processing job 20 ...\n",
      "  - Title: Machine Learning Engineer\n",
      "  - Company: N/A\n",
      "  - Experience: 0\n",
      "  - Skills: Python, R, LightGBM, Pandas, Statistics, Machine L...\n",
      "Processing job 21 ...\n",
      "  - Title: RHTAS Senior Software Engineer - Model Signing and Attestations - (Ireland)\n",
      "  - Company: N/A\n",
      "  - Experience: 1\n",
      "  - Skills: Python, R, Machine Learning\n",
      "Processing job 22 ...\n",
      "  - Title: RHTAS Senior Software Engineer - Model Signing and Attestations - (Ireland)\n",
      "  - Company: N/A\n",
      "  - Experience: 1\n",
      "  - Skills: Python, R\n",
      "Processing job 23 ...\n",
      "  - Title: RHTAS Senior Software Engineer - Model Signing and Attestations - (Ireland)\n",
      "  - Company: N/A\n",
      "  - Experience: 1\n",
      "  - Skills: Python, R\n",
      "Processing job 24 ...\n",
      "  - Title: Senior Machine Learning Engineer II\n",
      "  - Company: N/A\n",
      "  - Experience: 5\n",
      "  - Skills: R, Hypothesis Testing, A/B Testing, Machine Learni...\n",
      "Processing job 25 ...\n",
      "  - Title: RHOAI Senior Software Engineer - Model Training/OpenShift AI\n",
      "  - Company: N/A\n",
      "  - Experience: 1\n",
      "  - Skills: Python, R, PyTorch, Machine Learning, AWS, Azure, ...\n",
      "\n",
      "Current page scraping completed!\n",
      "Total jobs collected so far: 25\n",
      "Data appended to ../datasets/raw/DS_experience_skills.csv\n",
      "Current batch: 25 jobs\n",
      "job_details cleared for next page\n"
     ]
    }
   ],
   "source": [
    "# Store all job info here\n",
    "job_details = []\n",
    "\n",
    "# Extract experience requirement from page content\n",
    "def extract_experience(content):\n",
    "    # Mapping of English number words to Arabic numerals\n",
    "    word_to_num = {\n",
    "        'one': '1', 'two': '2', 'three': '3', 'four': '4', 'five': '5',\n",
    "        'six': '6', 'seven': '7', 'eight': '8', 'nine': '9', 'ten': '10',\n",
    "        'eleven': '11', 'twelve': '12', 'fifteen': '15', 'twenty': '20'\n",
    "    }\n",
    "    \n",
    "    # Expanded patterns to match various experience formats\n",
    "    patterns = [\n",
    "        # Standard patterns with 'experience'\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*experience',\n",
    "        r'(\\d+)\\s*years?\\s*of\\s*experience',\n",
    "        r'(\\d+)\\s*experience',\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|fifteen|twenty)\\s*years?\\s*experience',\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|fifteen|twenty)\\s*years?\\s*of\\s*experience',\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten|eleven|twelve|fifteen|twenty)\\s*experience',\n",
    "        \n",
    "        # Patterns without 'experience' keyword\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*in',\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*working',\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*background',\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*relevant',\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*professional',\n",
    "        r'(\\d+)\\s*[-+]?\\s*years?\\s*industry',\n",
    "        \n",
    "        # Minimum/maximum patterns\n",
    "        r'minimum\\s*(\\d+)\\s*years?',\n",
    "        r'at\\s*least\\s*(\\d+)\\s*years?',\n",
    "        r'minimum\\s*of\\s*(\\d+)\\s*years?',\n",
    "        r'(\\d+)\\s*[-+]\\s*years?\\s*minimum',\n",
    "        r'(\\d+)\\s*to\\s*(\\d+)\\s*years?',\n",
    "        \n",
    "        # Range patterns (take the lower number)\n",
    "        r'(\\d+)\\s*[-–]\\s*(\\d+)\\s*years?',\n",
    "        \n",
    "        # English number words with various contexts\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*years?\\s*in',\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*years?\\s*working',\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*years?\\s*background',\n",
    "        r'(one|two|three|four|five|six|seven|eight|nine|ten)\\s*years?\\s*relevant',\n",
    "        \n",
    "        # Additional patterns\n",
    "        r'(\\d+)\\+\\s*years?',\n",
    "        r'over\\s*(\\d+)\\s*years?',\n",
    "        r'more\\s*than\\s*(\\d+)\\s*years?',\n",
    "        r'(\\d+)\\s*or\\s*more\\s*years?'\n",
    "    ]\n",
    "    \n",
    "    # Search for patterns in content\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, content, re.IGNORECASE)\n",
    "        if matches:\n",
    "            # Handle different match types\n",
    "            if isinstance(matches[0], tuple):\n",
    "                # For range patterns, take the first (lower) number\n",
    "                value = matches[0][0].lower()\n",
    "            else:\n",
    "                value = matches[0].lower()\n",
    "            \n",
    "            # Convert English number words to Arabic numerals\n",
    "            if value in word_to_num:\n",
    "                return word_to_num[value]\n",
    "            # Return Arabic numeral if already numeric\n",
    "            elif value.isdigit():\n",
    "                return value\n",
    "    \n",
    "    # Fallback logic for general experience levels\n",
    "    if re.search(r'entry.level|junior|graduate|fresh|trainee|intern', content, re.IGNORECASE):\n",
    "        return \"0\"  # Entry Level = 0\n",
    "    elif re.search(r'senior|lead|principal|manager|director', content, re.IGNORECASE):\n",
    "        return \"5\"  # Senior Level = 5\n",
    "    elif re.search(r'mid.level|intermediate|experienced', content, re.IGNORECASE):\n",
    "        return \"3\"  # Mid Level = 3\n",
    "    \n",
    "    return \"0\"  # Not specified = 0\n",
    "\n",
    "# Extract skills requirement from page content\n",
    "def extract_skills(content):\n",
    "    skill_keywords = [\n",
    "        # Programming Languages\n",
    "    'Python', 'R', 'SQL', 'Julia', 'Matlab', 'SAS', 'SPSS',\n",
    "    \n",
    "    # Machine Learning Libraries\n",
    "    'Scikit-learn', 'TensorFlow', 'PyTorch', 'Keras', 'XGBoost',\n",
    "    'LightGBM', 'CatBoost', 'Pandas', 'NumPy', 'SciPy',\n",
    "    \n",
    "    # Deep Learning & AI\n",
    "    'Deep Learning', 'Neural Networks', 'CNN', 'RNN', 'LSTM',\n",
    "    'Transformer', 'NLP', 'Computer Vision', 'OpenAI', 'Hugging Face',\n",
    "    \n",
    "    # Data Visualization\n",
    "    'Matplotlib', 'Seaborn', 'Plotly', 'Bokeh', 'ggplot2',\n",
    "    'Tableau', 'Power BI', 'D3.js',\n",
    "    \n",
    "    # Statistics & Mathematics\n",
    "    'Statistics', 'Probability', 'Linear Algebra', 'Calculus',\n",
    "    'Hypothesis Testing', 'A/B Testing', 'Bayesian Statistics',\n",
    "    \n",
    "    # Machine Learning Techniques\n",
    "    'Machine Learning', 'Supervised Learning', 'Unsupervised Learning',\n",
    "    'Reinforcement Learning', 'Classification', 'Regression',\n",
    "    'Clustering', 'Dimensionality Reduction', 'Feature Engineering',\n",
    "    \n",
    "    # Big Data & Cloud\n",
    "    'Spark', 'Hadoop', 'AWS', 'Azure', 'Google Cloud', 'Databricks',\n",
    "    'MLflow', 'Kubeflow', 'SageMaker',\n",
    "    \n",
    "    # Notebooks & IDEs\n",
    "    'Jupyter', 'JupyterLab', 'Google Colab', 'RStudio', 'Anaconda',\n",
    "    \n",
    "    # Model Deployment\n",
    "    'Docker', 'Flask', 'FastAPI', 'Streamlit', 'Gradio', 'MLOps'\n",
    "    ]\n",
    "    found_skills = []\n",
    "    for skill in skill_keywords:\n",
    "        if re.search(rf'\\b{skill}\\b', content, re.IGNORECASE):\n",
    "            found_skills.append(skill)\n",
    "    return ', '.join(found_skills) if found_skills else \"Not specified\"\n",
    "\n",
    "# Run this function for each page after manual page turn\n",
    "# Collect job info from current page\n",
    "def scrape_current_page():\n",
    "    # Re-find job cards to avoid stale element reference\n",
    "    job_cards = browser.find_elements(By.CSS_SELECTOR, 'article.res-4cwuay')\n",
    "    print(f'Found {len(job_cards)} jobs on this page')\n",
    "    \n",
    "    for i in range(len(job_cards)):\n",
    "        try:\n",
    "            # Re-find job cards each time to avoid stale element\n",
    "            job_cards = browser.find_elements(By.CSS_SELECTOR, 'article.res-4cwuay')\n",
    "            if i >= len(job_cards):\n",
    "                break\n",
    "                \n",
    "            card = job_cards[i]\n",
    "            print(f'Processing job {i+1} ...')\n",
    "            \n",
    "            # Click the job card\n",
    "            card.click()\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Get page content\n",
    "            page_content = browser.page_source\n",
    "            \n",
    "            # Extract information\n",
    "            experience = extract_experience(page_content)\n",
    "            skills = extract_skills(page_content)\n",
    "            \n",
    "            # Get job title and company\n",
    "            try:\n",
    "                job_title = browser.find_element(By.CSS_SELECTOR, 'h1').text\n",
    "            except:\n",
    "                job_title = 'N/A'\n",
    "            \n",
    "            try:\n",
    "                company = browser.find_element(By.CSS_SELECTOR, '[data-testid=\"company-name\"]').text\n",
    "            except:\n",
    "                company = 'N/A'\n",
    "            \n",
    "            # Store the data\n",
    "            job_details.append({\n",
    "                'job_title': job_title,\n",
    "                'company': company,\n",
    "                'experience': experience,\n",
    "                'skills': skills\n",
    "            })\n",
    "            \n",
    "            print(f'  - Title: {job_title}')\n",
    "            print(f'  - Company: {company}')\n",
    "            print(f'  - Experience: {experience}')\n",
    "            print(f'  - Skills: {skills[:50]}...' if len(skills) > 50 else f'  - Skills: {skills}')\n",
    "            \n",
    "            # Go back to job list\n",
    "            browser.back()\n",
    "            time.sleep(3)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error on job {i+1}: {e}')\n",
    "            try:\n",
    "                browser.back()\n",
    "                time.sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "            continue\n",
    "\n",
    "# Save data to CSV (追加模式)\n",
    "def save_data():\n",
    "    if job_details:\n",
    "        df = pd.DataFrame(job_details)\n",
    "        filename = '../datasets/raw/DS_experience_skills.csv'\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        \n",
    "        # Check if file exists to decide whether to write header\n",
    "        file_exists = os.path.isfile(filename)\n",
    "        \n",
    "        # Append to CSV (mode='a' for append)\n",
    "        df.to_csv(filename, mode='a', header=not file_exists, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f'Data appended to {filename}')\n",
    "        print(f'Current batch: {len(job_details)} jobs')\n",
    "        \n",
    "        # Clear the job_details list for next page\n",
    "        job_details.clear()\n",
    "        print('job_details cleared for next page')\n",
    "    else:\n",
    "        print('No data to save')\n",
    "\n",
    "# Execute the scraping for current page\n",
    "print(\"Starting to scrape current page...\")\n",
    "scrape_current_page()\n",
    "print(\"\\nCurrent page scraping completed!\")\n",
    "print(f\"Total jobs collected so far: {len(job_details)}\")\n",
    "save_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
